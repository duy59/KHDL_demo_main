import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, association_rules
import json
import time

def save_results_to_json(freqItems, rules, output_file, min_support_ratio=0.005, min_confidence=0.5):
    """
    L∆∞u k·∫øt qu·∫£ v√†o file JSON theo ƒë·ªãnh d·∫°ng gi·ªëng code thu·∫ßn.
    """
    # Chuy·ªÉn ƒë·ªïi t·∫≠p h·ª£p th√†nh danh s√°ch ƒë·ªÉ c√≥ th·ªÉ l∆∞u v√†o JSON
    freq_items_json = [list(itemset) for itemset in freqItems]

    rules_json = []
    for _, row in rules.iterrows():
        rules_json.append({
            "antecedent": list(row['antecedents']),
            "consequent": list(row['consequents']),
            "confidence": row['confidence']
        })

    result = {
        "metadata": {
            "min_support_ratio": min_support_ratio,
            "min_confidence": min_confidence,
            "total_frequent_itemsets": len(freqItems),
            "total_rules": len(rules_json)
        },
        "frequent_itemsets": freq_items_json,
        "association_rules": rules_json
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=4, ensure_ascii=False)

    print(f"‚úîÔ∏è ƒê√£ l∆∞u k·∫øt qu·∫£ JSON v√†o: {output_file}")


def run_library_algorithm(transactions_list, min_support_ratio, min_confidence):
    """
    Ch·∫°y thu·∫≠t to√°n FP-Growth b·∫±ng th∆∞ vi·ªán mlxtend

    Args:
        transactions_list: List of transactions (list of lists)
        min_support_ratio: Support threshold
        min_confidence: Confidence threshold

    Returns:
        dict: K·∫øt qu·∫£ v·ªõi frequent_itemsets, association_rules, execution_time
    """
    print(f"\n{'='*60}")
    print(f"LIBRARY ALGORITHM (MLXTEND) - EXECUTION")
    print(f"{'='*60}")
    print(f"üìö Using mlxtend library")
    print(f"‚öôÔ∏è Support threshold: {min_support_ratio}")
    print(f"‚öôÔ∏è Confidence threshold: {min_confidence}")
    print(f"üìä Total transactions: {len(transactions_list)}")

    start_time = time.time()

    try:
        # One-hot encoding
        print("üîÑ Performing one-hot encoding...")
        te = TransactionEncoder()
        te_ary = te.fit(transactions_list).transform(transactions_list)
        df_encoded = pd.DataFrame(te_ary, columns=te.columns_)
        print(f"‚úÖ Encoded {len(df_encoded)} transactions with {len(te.columns_)} unique items")

        # T√¨m t·∫≠p m·ª•c ph·ªï bi·∫øn
        print("‚õèÔ∏è Mining frequent itemsets...")
        frequent_itemsets = fpgrowth(df_encoded, min_support=min_support_ratio, use_colnames=True)
        print(f"‚úÖ Found {len(frequent_itemsets)} frequent itemsets")

        # Sinh lu·∫≠t k·∫øt h·ª£p
        print("üîó Generating association rules...")
        if len(frequent_itemsets) > 0:
            rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
            print(f"‚úÖ Generated {len(rules)} association rules")
        else:
            rules = pd.DataFrame()
            print("‚ùå No frequent itemsets found, cannot generate rules")

        end_time = time.time()
        execution_time = end_time - start_time

        # Format k·∫øt qu·∫£
        formatted_itemsets = []
        for _, row in frequent_itemsets.iterrows():
            formatted_itemsets.append({
                'itemset': list(row['itemsets']),
                'support': round(row['support'], 4)
            })

        # S·∫Øp x·∫øp itemsets theo support gi·∫£m d·∫ßn
        formatted_itemsets.sort(key=lambda x: x['support'], reverse=True)

        # Th√™m s·ªë th·ª© t·ª±
        for i, itemset in enumerate(formatted_itemsets, 1):
            itemset['rank'] = i

        formatted_rules = []
        for _, row in rules.iterrows():
            formatted_rules.append({
                'antecedent': list(row['antecedents']),
                'consequent': list(row['consequents']),
                'confidence': round(row['confidence'], 4),
                'support': round(row['support'], 4),
                'lift': round(row['lift'], 4)
            })

        # S·∫Øp x·∫øp theo confidence t·ª´ cao xu·ªëng th·∫•p
        formatted_rules.sort(key=lambda x: x['confidence'], reverse=True)

        print(f"‚è±Ô∏è Library execution time: {execution_time:.4f} seconds")
        print(f"‚úÖ Library algorithm completed successfully")

        return {
            'frequent_itemsets': formatted_itemsets,
            'association_rules': formatted_rules,
            'execution_time': execution_time,
            'algorithm': 'mlxtend_fpgrowth',
            'parameters': {
                'support_threshold': min_support_ratio,
                'confidence_threshold': min_confidence
            }
        }

    except Exception as e:
        end_time = time.time()
        execution_time = end_time - start_time
        print(f"‚ùå Library algorithm failed: {str(e)}")
        return {
            'error': str(e),
            'execution_time': execution_time,
            'algorithm': 'mlxtend_fpgrowth'
        }

def main():
    # ƒê·ªçc d·ªØ li·ªáu
    input_file = "invoice_summary.csv"
    print(f"ƒê·ªçc d·ªØ li·ªáu t·ª´ {input_file}...")
    df = pd.read_csv(input_file)
    transactions = df["ListItem"].dropna().apply(lambda x: x.split(",")).tolist()

    # C√†i ƒë·∫∑t ng∆∞·ª°ng
    min_support_ratio = 0.005
    min_confidence = 0.5

    # Ch·∫°y thu·∫≠t to√°n th∆∞ vi·ªán
    result = run_library_algorithm(transactions, min_support_ratio, min_confidence)

    # Xu·∫•t file JSON
    json_file = "fpgrowth_results_lib.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=4, ensure_ascii=False)
    print(f"‚úîÔ∏è ƒê√£ l∆∞u k·∫øt qu·∫£ JSON v√†o: {json_file}")


if __name__ == "__main__":
    main()
